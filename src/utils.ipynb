{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363965ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a6956",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.set_cmap(\"cividis\")\n",
    "from IPython.display import set_matplotlib_formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749719e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_matplotlib_formats(\"svg\", \"pdf\")\n",
    "import matplotlib\n",
    "from matplotlib.colors import to_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2b8585",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_orig()\n",
    "import jax\n",
    "import optax\n",
    "import torch\n",
    "from flax.training import checkpoints, train_state\n",
    "from jax import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece2d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple, list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a5562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_patch(x, patch_size, flatten_channels=True):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        x - torch.Tensor representing the image of shape [B, H, W, C]\n",
    "        patch_size - Number of pixels per dimension of the patches (integer)\n",
    "        flatten_channels - If True, the patches will be returned in a flattened format\n",
    "                           as a feature vector instead of a image grid.\n",
    "    \"\"\"\n",
    "    B, H, W, C = x.shape\n",
    "    x = x.reshape(B, H // patch_size, patch_size, W // patch_size, patch_size, C)\n",
    "    x = x.transpose(0, 1, 3, 2, 4, 5)  # [B, H', W', p_H, p_W, C]\n",
    "    x = x.reshape(B, -1, *x.shape[3:])  # [B, H'*W', p_H, p_W, C]\n",
    "    if flatten_channels:\n",
    "        x = x.reshape(B, x.shape[1], -1)  # [B, H'*W', p_H*p_W*C]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c531fb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def numpy_to_torch(array):\n",
    "    array = jax.device_get(array)\n",
    "    tensor = torch.from_numpy(array)\n",
    "    tensor = tensor.permute(0, 3, 1, 2)\n",
    "    return tensor"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
